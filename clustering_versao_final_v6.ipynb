{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "417561c2-bc21-4962-96f6-bcd84cb996b0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 1.Imports & Reading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91fb99f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mTraceback (most recent call last):\n",
      "\u001b[1;31m  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "\u001b[1;31m  File \"<frozen runpy>\", line 88, in _run_code\n",
      "\u001b[1;31m  File \"/opt/anaconda3/envs/DM2425/lib/python3.12/site-packages/ipykernel_launcher.py\", line 16, in <module>\n",
      "\u001b[1;31m    from ipykernel import kernelapp as app\n",
      "\u001b[1;31m  File \"/opt/anaconda3/envs/DM2425/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 21, in <module>\n",
      "\u001b[1;31m    from IPython.core.application import (  # type:ignore[attr-defined]\n",
      "\u001b[1;31m  File \"/opt/anaconda3/envs/DM2425/lib/python3.12/site-packages/IPython/__init__.py\", line 55, in <module>\n",
      "\u001b[1;31m    from .terminal.embed import embed\n",
      "\u001b[1;31m  File \"/opt/anaconda3/envs/DM2425/lib/python3.12/site-packages/IPython/terminal/embed.py\", line 15, in <module>\n",
      "\u001b[1;31m    from IPython.core.interactiveshell import DummyMod, InteractiveShell\n",
      "\u001b[1;31m  File \"/opt/anaconda3/envs/DM2425/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 110, in <module>\n",
      "\u001b[1;31m    from IPython.core.history import HistoryManager\n",
      "\u001b[1;31m  File \"/opt/anaconda3/envs/DM2425/lib/python3.12/site-packages/IPython/core/history.py\", line 10, in <module>\n",
      "\u001b[1;31m    import sqlite3\n",
      "\u001b[1;31m  File \"/opt/anaconda3/envs/DM2425/lib/python3.12/sqlite3/__init__.py\", line 57, in <module>\n",
      "\u001b[1;31m    from sqlite3.dbapi2 import *\n",
      "\u001b[1;31m  File \"/opt/anaconda3/envs/DM2425/lib/python3.12/sqlite3/dbapi2.py\", line 27, in <module>\n",
      "\u001b[1;31m    from _sqlite3 import *\n",
      "\u001b[1;31mImportError: dlopen(/opt/anaconda3/envs/DM2425/lib/python3.12/lib-dynload/_sqlite3.cpython-312-darwin.so, 0x0002): Symbol not found: _sqlite3_enable_load_extension\n",
      "\u001b[1;31m  Referenced from: <4C8A356C-740E-3A20-8BFB-F406623A870F> /opt/anaconda3/envs/DM2425/lib/python3.12/lib-dynload/_sqlite3.cpython-312-darwin.so\n",
      "\u001b[1;31m  Expected in:     <3791084A-969D-36E3-B3AD-AC9CB500EC27> /usr/lib/libsqlite3.dylib. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Import Packages\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from ydata_profiling import ProfileReport\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import warnings\n",
    "from sklearn.exceptions import DataConversionWarning\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from math import ceil \n",
    "import os\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
    "from sklearn.metrics import silhouette_score, silhouette_samples\n",
    "import matplotlib.cm as cm\n",
    "from minisom import MiniSom\n",
    "import sompy\n",
    "from sompy.visualization.mapview import View2D\n",
    "from sompy.visualization.bmuhits import BmuHitsView\n",
    "from sompy.visualization.hitmap import HitMapView\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import DBSCAN, estimate_bandwidth\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.base import clone\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "import graphviz\n",
    "import pickle\n",
    "\n",
    "import warnings\n",
    "import logging\n",
    "logging.getLogger('matplotlib').setLevel(logging.ERROR)\n",
    "\n",
    "warnings.filterwarnings(action='ignore', category=UserWarning, module='sklearn')\n",
    "warnings.filterwarnings(\"ignore\", module=\"sklearn.cluster._kmeans\")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.filterwarnings(\"ignore\", module=\"graphviz\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eddb2b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read/Import dataset\n",
    "import pickle\n",
    "df = pickle.load(open(\"preprocessed_data_numerical.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f14e467-afd6-4c58-94e1-309cd266f28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_features = list(df.columns)\n",
    "metric_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f49ebbf",
   "metadata": {},
   "source": [
    "# 2.Segmentation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1000a3cd-2b8b-4ae9-bf99-7b0a5ba89ee6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2.1 Defining our segmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79c1daa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics_preferences = ['customer_age', 'Recency', 'log_order_rate_per_week', 'log_amount_spent_per_week']\n",
    "\n",
    "\n",
    "purchase_behavior = ['average_product_price','chain_percentage','log_vendor_count']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2bec89c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_profiles(df, label_columns, figsize, compar_titles=None):\n",
    "    \"\"\"\n",
    "    Pass df with labels columns of one or multiple clustering labels. \n",
    "    Then specify this label columns to perform the cluster profile according to them.\n",
    "    \"\"\"\n",
    "    if compar_titles == None:\n",
    "        compar_titles = [\"\"]*len(label_columns)\n",
    "        \n",
    "    sns.set()\n",
    "    fig, axes = plt.subplots(nrows=len(label_columns), ncols=2, figsize=figsize, squeeze=False)\n",
    "    for ax, label, titl in zip(axes, label_columns, compar_titles):\n",
    "        # Filtering df\n",
    "        drop_cols = [i for i in label_columns if i!=label]\n",
    "        dfax = df.drop(drop_cols, axis=1)\n",
    "        \n",
    "        # Getting the cluster centroids and counts\n",
    "        centroids = dfax.groupby(by=label, as_index=False).mean()\n",
    "        counts = dfax.groupby(by=label, as_index=False).count().iloc[:,[0,1]]\n",
    "        counts.columns = [label, \"counts\"]\n",
    "        \n",
    "        # Setting Data\n",
    "        pd.plotting.parallel_coordinates(centroids, label, color=sns.color_palette(), ax=ax[0])\n",
    "        sns.barplot(x=label, y=\"counts\", data=counts, ax=ax[1])\n",
    "\n",
    "        #Setting Layout\n",
    "        handles, _ = ax[0].get_legend_handles_labels()\n",
    "        cluster_labels = [\"Cluster {}\".format(i) for i in range(len(handles))]\n",
    "        ax[0].annotate(text=titl, xy=(0.95,1.1), xycoords='axes fraction') \n",
    "        ax[0].legend(handles, cluster_labels) # Adaptable to number of clusters\n",
    "        ax[0].axhline(color=\"black\", linestyle=\"--\")\n",
    "        ax[0].set_title(\"Cluster Means - {} Clusters\".format(len(handles)))\n",
    "        ax[0].set_xticklabels(ax[0].get_xticklabels(), rotation=-20)\n",
    "        ax[1].set_xticklabels(cluster_labels)\n",
    "        ax[1].set_xlabel(\"\")\n",
    "        ax[1].set_ylabel(\"Absolute Frequency\")\n",
    "        ax[1].set_title(\"Cluster Sizes - {} Clusters\".format(len(handles)))\n",
    "    \n",
    "    plt.subplots_adjust(hspace=0.4, top=0.90)\n",
    "    plt.suptitle(\"Cluster Simple Profilling\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ad2a05a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2.2 Segmentation 1 - Demographic preferences "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28d127d1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Hierarchical + K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "909c0ab1-7003-4b96-bd11-5252ec3a86d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_socio1 = df[demographics_preferences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "80f873e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ss(df):\n",
    "    \"\"\"Computes the sum of squares for all variables given a dataset\n",
    "    \"\"\"\n",
    "    ss = np.sum(df.var() * (df.count() - 1))\n",
    "    return ss  # return sum of sum of squares of each df variable\n",
    "\n",
    "def r2(df, labels):\n",
    "    sst = get_ss(df)\n",
    "    ssw = np.sum(df.groupby(labels).apply(get_ss))\n",
    "    return 1 - ssw/sst\n",
    "    \n",
    "def get_r2_scores(df, clusterer, min_k=2, max_k=10):\n",
    "    \"\"\"\n",
    "    Loop over different values of k. To be used with sklearn clusterers.\n",
    "    \"\"\"\n",
    "    r2_clust = {}\n",
    "    for n in range(min_k, max_k):\n",
    "        clust = clone(clusterer).set_params(n_clusters=n)\n",
    "        labels = clust.fit_predict(df)\n",
    "        r2_clust[n] = r2(df, labels)\n",
    "    return r2_clust\n",
    "\n",
    "\n",
    "# Set up the clusterers\n",
    "kmeans = KMeans(\n",
    "    init='k-means++',\n",
    "    n_init=20,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "hierarchical = AgglomerativeClustering(\n",
    "    metric='euclidean'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5c5a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining the R² scores for each cluster solution on demographic preferences\n",
    "r2_scores = {}\n",
    "r2_scores['kmeans'] = get_r2_scores(df_socio1, kmeans)\n",
    "\n",
    "for linkage in ['complete', 'average', 'single', 'ward']:\n",
    "    r2_scores[linkage] = get_r2_scores(\n",
    "        df_socio1, hierarchical.set_params(linkage=linkage)\n",
    "    )\n",
    "\n",
    "pd.DataFrame(r2_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a85f6f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the R² scores for each cluster solution on demographic variables\n",
    "pd.DataFrame(r2_scores).plot.line(figsize=(10,7))\n",
    "\n",
    "plt.title(\"Demographic Variables:\\nR² plot for various clustering methods\\n\")\n",
    "plt.legend(title=\"Cluster methods\")\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"R² metric\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d03154d-210e-41a6-94de-9acaf9bec1ae",
   "metadata": {},
   "source": [
    "Based on the graph above is not clear if we should choose 3 or 4 clusters. The R² isn't very different from 3 to 4 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a650cd12",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmclust = KMeans(n_clusters=3, init='k-means++', n_init=15, random_state=1)\n",
    "kmclust.fit(df_socio1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69a1555-9197-4d92-8e94-4fe5c16a121e",
   "metadata": {},
   "source": [
    "We are going to plot the silhouette_score to decide the final number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282cb0f7-7be7-42cc-9675-475b16e17e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from:\n",
    "# https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html#sphx-glr-auto-examples-cluster-plot-kmeans-silhouette-analysis-py\n",
    "\n",
    "range_clusters = range(1, 11)\n",
    "\n",
    "# Storing average silhouette metric\n",
    "avg_silhouette = []\n",
    "for nclus in range_clusters:\n",
    "    # Skip nclus == 1\n",
    "    if nclus == 1:\n",
    "        continue\n",
    "    \n",
    "    # Create a figure\n",
    "    fig = plt.figure(figsize=(13, 7))\n",
    "\n",
    "    # Initialize the KMeans object with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "    kmclust = KMeans(n_clusters=nclus, init='k-means++', n_init=15, random_state=1)\n",
    "    cluster_labels = kmclust.fit_predict(df_socio1)\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed clusters\n",
    "    silhouette_avg = silhouette_score(df_socio1, cluster_labels)\n",
    "    avg_silhouette.append(silhouette_avg)\n",
    "    print(f\"For n_clusters = {nclus}, the average silhouette_score is : {silhouette_avg}\")\n",
    "\n",
    "# The average silhouette plot\n",
    "# The inertia plot\n",
    "plt.figure(figsize=(9,5))\n",
    "plt.plot(range_clusters[1:], ## Plot X-axis; Why range_clusters[1:] ? Remember we skipped k=1 in the cell above\n",
    "         avg_silhouette)     ## Plot Y-axis\n",
    "\n",
    "plt.ylabel(\"Average silhouette\")\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.title(\"Average silhouette plot over clusters in demographic variables\", size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df2d243-d73b-4863-9b0b-dd522af3c930",
   "metadata": {},
   "source": [
    "It is not very common to see the silhouette_score decreasing as we add more clusters. However, the dataset might have a strong natural separation into 2 groups. Adding more clusters forces the algorithm to split well-formed groups, leading to lower silhouette scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb9e057-3cf4-42e0-b74c-88ee094a5dcb",
   "metadata": {},
   "source": [
    "Based on that we are going to choose 3 clusters. The difference in silhoete score between 3 and 4 clusters isn't very big. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa03a102",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_socio1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6205928",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-running the Hierarchical clustering based on the correct number of clusters\n",
    "kmclust = KMeans(n_clusters=3, init='k-means++', n_init=15, random_state=1)\n",
    "kmclust_labels = kmclust.fit_predict(df_socio1)\n",
    "df_socio1['kmlust_labels'] = kmclust_labels\n",
    "\n",
    "df_socio1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d1d719",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_socio1['kmlust_labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527c8ec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_profiles(df_socio1, ['kmlust_labels'], (20,7))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505b8386",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_socio1.groupby('kmlust_labels')[demographics_preferences].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b130141",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### SOM + K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "455e7640",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_somk_1 = df[demographics_preferences]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb65725-23a0-460e-88ef-38ee0514783d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### SOM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f9aad2-5179-412b-aba8-b04bbdfde7ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(80)\n",
    "\n",
    "sm = sompy.SOMFactory().build(\n",
    "    df_somk_1.values, \n",
    "    mapsize=[10, 10], \n",
    "    initialization='random', \n",
    "    neighborhood='gaussian',\n",
    "    training='batch',\n",
    "    lattice='hexa',\n",
    "    component_names=demographics_preferences\n",
    ")\n",
    "sm.train(n_job=1, verbose='info', train_rough_len=120, train_finetune_len=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6ea0035-822b-4973-b3bf-293b6aa0776d",
   "metadata": {},
   "source": [
    "The final quantization error is 0.798841, indicating the average distance between the data points and their corresponding best-matching unit (BMU) after training. Lower values generally indicate better mapping of input data onto the SOM."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8250b7-7f1c-4927-aff2-6864d5bceec9",
   "metadata": {},
   "source": [
    "#### Choosing the best number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcb38e9-3d11-49e1-9863-72093c4d2729",
   "metadata": {},
   "outputs": [],
   "source": [
    "inertia = []\n",
    "for n_clus in range(1,11): \n",
    "    kmclust = KMeans(n_clusters=n_clus, init='k-means++', n_init=20, random_state=80)\n",
    "    kmclust.fit(df_somk_1)\n",
    "    inertia.append(kmclust.inertia_)\n",
    "\n",
    "plt.figure(figsize=(9,5))\n",
    "plt.plot(range(1,11),inertia,color = 'blue')\n",
    "plt.ylabel(\"Inertia: SSw\")\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.title(\"Inertia plot over clusters in\", size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45c3bc4-0df4-4e33-9f8c-686a21ebb53b",
   "metadata": {},
   "source": [
    "Beyond 4 clusters, the decrease in inertia slows down, which suggests diminishing returns for adding more clusters.\n",
    "\n",
    "The \"elbow point\" appears to be at 4 clusters, where the rate of improvement in inertia reduction becomes less pronounced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46cfade-f388-4e88-bed9-3796baa27f5b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### U-matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60792a23-eaf6-4044-aa1b-47e26d89f3de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f29e8bc3-f00b-4ac8-8aa2-0e89c480fa6c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### HitMapView"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b36f46-3238-45d6-98e8-3639b4ccd8fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4,init='k-means++', n_init=20, random_state=42)\n",
    "nodeclus_labels = kmeans.fit_predict(sm.codebook.matrix)\n",
    "sm.cluster_labels = nodeclus_labels  # setting the cluster labels of sompy\n",
    "\n",
    "hits = HitMapView(8,8,\"Clustering\", text_size=10)\n",
    "hits.show(sm, anotate=True, onlyzeros=False, labelsize=7, cmap=cm.Greens)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f80cca4-2cb5-48af-8a9d-ffca738dd9cb",
   "metadata": {},
   "source": [
    "Each hexagon represents a neuron in the SOM grid, and the assigned cluster labels (0, 1, 2, 3) are shown inside the respective cells."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19eedbad-f5fd-484f-9efd-08229a5061d0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Final clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e404245-c9be-4649-aa0a-5649347914a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = sm.codebook.matrix\n",
    "\n",
    "df_somk = pd.DataFrame(nodes, columns=demographics_preferences)\n",
    "df_somk['som_kmeans_labels'] = nodeclus_labels\n",
    "df_somk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fb9148-cfcd-4668-a727-87b1b7c5fe22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_somk['som_kmeans_labels'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39dda470-5f03-40b9-9903-bec90e71e0a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmus_map = sm.find_bmu(df_somk_1.values)[0]  #get bmus for each observation in df\n",
    "\n",
    "df_bmus = pd.DataFrame(\n",
    "    np.concatenate((df_somk_1, np.expand_dims(bmus_map,1)), axis=1),\n",
    "    index=df_somk_1.index, columns=np.append(df_somk_1.columns,\"BMU\")\n",
    ")\n",
    "df_bmus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "968eab66-8141-41b3-9793-f3b51c7220d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_somk_1 = df_bmus.merge(df_somk['som_kmeans_labels'], 'left', left_on=\"BMU\", right_index=True)\n",
    "\n",
    "df_somk_1.drop('BMU', axis=1, inplace=True)\n",
    "\n",
    "df_somk_1.groupby('som_kmeans_labels')[demographics_preferences].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873257de-fe36-4fd4-ac9c-31e938ce4b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_profiles(df_somk_1, ['som_kmeans_labels'], (20,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78d7d15",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### SOM + Hierarquical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "26529911",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_socio3 = df[demographics_preferences]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b2a54d-e277-47bd-a09f-5767cd3ff96c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### SOM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091c0a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(80)\n",
    "\n",
    "sm = sompy.SOMFactory().build(\n",
    "    df_socio3.values, \n",
    "    mapsize=[10, 10], \n",
    "    initialization='random', \n",
    "    neighborhood='gaussian',\n",
    "    training='batch',\n",
    "    lattice='hexa',\n",
    "    component_names=demographics_preferences\n",
    ")\n",
    "sm.train(n_job=1, verbose='info', train_rough_len=120, train_finetune_len=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7b2e89-616b-4201-be2f-fcfb0b65ff2b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Choosing the best number of clusters with Hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae02f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "linkage = 'ward'\n",
    "distance = 'euclidean'\n",
    "hclust = AgglomerativeClustering(linkage=linkage, metric=distance, distance_threshold=0, n_clusters=None)\n",
    "hclust.fit_predict(df_socio3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf44af55",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = np.zeros(hclust.children_.shape[0])\n",
    "n_samples = len(hclust.labels_)\n",
    "\n",
    "# hclust.children_ contains the observation ids that are being merged together\n",
    "# At the i-th iteration, children[i][0] and children[i][1] are merged to form node n_samples + i\n",
    "for i, merge in enumerate(hclust.children_):\n",
    "    # track the number of observations in the current cluster being formed\n",
    "    current_count = 0\n",
    "    for child_idx in merge:\n",
    "        if child_idx < n_samples:\n",
    "            # If this is True, then we are merging an observation\n",
    "            current_count += 1  # leaf node\n",
    "        else:\n",
    "            # Otherwise, we are merging a previously formed cluster\n",
    "            current_count += counts[child_idx - n_samples]\n",
    "    counts[i] = current_count\n",
    "\n",
    "# the hclust.children_ is used to indicate the two points/clusters being merged (dendrogram's u-joins)\n",
    "# the hclust.distances_ indicates the distance between the two points/clusters (height of the u-joins)\n",
    "# the counts indicate the number of points being merged (dendrogram's x-axis)\n",
    "linkage_matrix = np.column_stack(\n",
    "    [hclust.children_, hclust.distances_, counts]\n",
    ").astype(float)\n",
    "\n",
    "# Plot the corresponding dendrogram\n",
    "sns.set()\n",
    "fig = plt.figure(figsize=(11,5))\n",
    "# The Dendrogram parameters need to be tuned\n",
    "y_threshold = 90\n",
    "dendrogram(linkage_matrix, truncate_mode='level', p=5, color_threshold=y_threshold, above_threshold_color='k')\n",
    "plt.hlines(y_threshold, 0, 1000, colors=\"r\", linestyles=\"dashed\")\n",
    "plt.title(f'Hierarchical Clustering - {linkage.title()}\\'s Dendrogram')\n",
    "plt.xlabel('Number of points in node (or index of point if no parenthesis)')\n",
    "plt.ylabel(f'{distance.title()} Distance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb01985-7235-463d-a087-3daf9a39c4b6",
   "metadata": {},
   "source": [
    "The threshold (red line) intersects just below a noticeable \"gap\" in the dendrogram.\n",
    "Above this threshold, the vertical distances between clusters are much larger, meaning clusters are more distinct.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90661903-d772-40c6-a4cd-8a6fb9d9be20",
   "metadata": {},
   "source": [
    "Based on this analysis, 6 clusters is the right choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac202e44-7b99-4463-8bdc-d9762362ebfd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### HitMapView"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c88f5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "hierclust = AgglomerativeClustering(n_clusters=6, linkage='ward')\n",
    "node_hier_label= hierclust.fit_predict(sm.codebook.matrix)\n",
    "sm.cluster_labels = node_hier_label  # setting the cluster labels of sompy\n",
    "\n",
    "hits  = HitMapView(6,6,\"Clustering\",text_size=10)\n",
    "hits.show(sm, anotate=True, onlyzeros=False, labelsize=7, cmap=cm.Greens)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732c3697-dac1-4b1a-8a6d-d51636ceff8d",
   "metadata": {},
   "source": [
    "#### Final clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a564c03a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = sm.codebook.matrix\n",
    "\n",
    "hnodes = pd.DataFrame(nodes, columns=demographics_preferences)\n",
    "hnodes['som_hierar_labels'] = node_hier_label\n",
    "hnodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "19d6edde",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmus_ = sm.find_bmu(df_socio3.values)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3fdc8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bmus_hc = pd.DataFrame(\n",
    "    np.concatenate((df_socio3, np.expand_dims(bmus_,1)), axis=1),\n",
    "    index=df_socio3.index, columns=np.append(df_socio3.columns,\"BMU\")\n",
    ")\n",
    "df_bmus_hc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "35d47efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cluster labels for each observation\n",
    "df_somh = df_bmus.merge(hnodes['som_hierar_labels'], 'left', left_on=\"BMU\", right_index=True)\n",
    "\n",
    "df_somh.drop('BMU', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7823eb65",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_profiles(df_somh, ['som_hierar_labels'], (20,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5efd4c4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d746285d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_socio4 = df[demographics_preferences]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed5c34f1-6eeb-4b48-bea5-0904f1cec58f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Choosing the right number of eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ae745f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Radius of cluster\n",
    "neigh = NearestNeighbors(n_neighbors=27)\n",
    "neigh.fit(df_socio4)\n",
    "distances, _ = neigh.kneighbors(df_socio4)\n",
    "distances = np.sort(distances[:, -1])\n",
    "plt.plot(distances[10000:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4ad68c-1848-41e1-8d43-e54b4d2d2b74",
   "metadata": {},
   "source": [
    "This plot above is typically used for determining an appropriate value for the epsilon (eps) parameter in DBSCAN clustering. The idea is to find the \"elbow point\" on the graph, which indicates the distance value where the curve transitions from a steep increase to a flatter slope. This point is a good candidate for the eps parameter, as it represents a natural clustering distance threshold in the data. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f788201a-ad24-4045-92fd-a783d4f5a98b",
   "metadata": {},
   "source": [
    "We are going to zoom in as the right eps is not clear in the graph above. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675fb12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(distances[10000:])\n",
    "plt.axis([18000, 22000, 0,1.6])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dca08d0-90bd-4c0f-b6cc-836e786ead69",
   "metadata": {},
   "source": [
    "After zooming in, we can see in the graph above that the elbow point is around 1.0, so that is the number that we are going to choose for eps."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7276725e-1953-4d68-a05a-595285df106a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Choosing the right number of min_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e512f370-30c1-4caf-ad03-0668d38e5d98",
   "metadata": {},
   "source": [
    "A function is going to be used to evaluate the values of \n",
    "the min_samples, with the selected eps value fixed, giving a view of the variation of the number of clusters \n",
    "and their respective noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ebc534",
   "metadata": {},
   "outputs": [],
   "source": [
    "for min_samples in range(2, 15):  \n",
    "        dbscan = DBSCAN(eps=1.0, min_samples=min_samples)\n",
    "        dbscan_labels = dbscan.fit_predict(df_socio4)\n",
    "            \n",
    "        dbscan_n_clusters = len(set(dbscan_labels)) - (1 if -1 in dbscan_labels else 0)\n",
    "            \n",
    "        n_noise = list(dbscan_labels).count(-1)\n",
    "            \n",
    "        if dbscan_n_clusters > 0:\n",
    "            print(f\"min_samples: {min_samples}, clusters: {dbscan_n_clusters}, noise:{n_noise}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "094d121d-8d8b-4542-a2c1-29a47581cbe3",
   "metadata": {},
   "source": [
    "min_samples = 3, 4 and 5 might seem a reasonable choice. We are going to see the Silhouette Score for each of them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d2d3d6a-13f4-4298-b76d-875e418c9b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=1.0, min_samples=3, n_jobs=4)\n",
    "dbscan_labels = dbscan.fit_predict(df_socio4)\n",
    "score = silhouette_score(df_socio4.iloc[:, :-1], dbscan_labels)\n",
    "print(f'Silhouette Score: {score}')\n",
    "dbscan_clusters = len(np.unique(dbscan_labels))\n",
    "print(\"Number of estimated clusters : %d\" % dbscan_clusters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3981a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=1.0, min_samples=4, n_jobs=4)\n",
    "dbscan_labels = dbscan.fit_predict(df_socio4)\n",
    "score = silhouette_score(df_socio4.iloc[:, :-1], dbscan_labels)\n",
    "print(f'Silhouette Score: {score}')\n",
    "dbscan_clusters = len(np.unique(dbscan_labels))\n",
    "print(\"Number of estimated clusters : %d\" % dbscan_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2625a0-0321-439a-85d4-d4b8719955be",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=1.0, min_samples=5, n_jobs=4)\n",
    "dbscan_labels = dbscan.fit_predict(df_socio4)\n",
    "score = silhouette_score(df_socio4.iloc[:, :-1], dbscan_labels)\n",
    "print(f'Silhouette Score: {score}')\n",
    "dbscan_clusters = len(np.unique(dbscan_labels))\n",
    "print(\"Number of estimated clusters : %d\" % dbscan_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ceb9b9-bc1d-45db-80c9-43b149a7f247",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Final clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "014c4064",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dbscan = pd.concat([df_socio4, pd.Series(dbscan_labels, name='dbscan_labels', index=df_socio4.index)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0800ed94",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_profiles(\n",
    "    df = df_dbscan, \n",
    "    label_columns = ['dbscan_labels'], \n",
    "    figsize = (20, 7), \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d973ac7-fe35-4173-bb98-881ae2239cc1",
   "metadata": {},
   "source": [
    "### Combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71151b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([df_socio1, df_somk_1, df_somh, df_dbscan], ignore_index=True)\n",
    "\n",
    "label_columns = ['kmlust_labels', 'som_kmeans_labels', 'som_hierar_labels', 'dbscan_labels']\n",
    "\n",
    "cluster_profiles(combined_df, label_columns, figsize=(20, 20),compar_titles = [\"Hierarchical + K-means\", \"SOM + K-means\", \"SOM + Hierarchical\", \"DBSCAN\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c2a851",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2.3 Segmentation 2 - Purchase_behavior "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e89ca8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Hierachical + K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "b83d53d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng1 = df[purchase_behavior]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c78ed76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ss(df):\n",
    "    \"\"\"Computes the sum of squares for all variables given a dataset\n",
    "    \"\"\"\n",
    "    ss = np.sum(df.var() * (df.count() - 1))\n",
    "    return ss  # return sum of sum of squares of each df variable\n",
    "\n",
    "def r2(df, labels):\n",
    "    sst = get_ss(df)\n",
    "    ssw = np.sum(df.groupby(labels).apply(get_ss))\n",
    "    return 1 - ssw/sst\n",
    "    \n",
    "def get_r2_scores(df, clusterer, min_k=2, max_k=10):\n",
    "    \"\"\"\n",
    "    Loop over different values of k. To be used with sklearn clusterers.\n",
    "    \"\"\"\n",
    "    r2_clust = {}\n",
    "    for n in range(min_k, max_k):\n",
    "        clust = clone(clusterer).set_params(n_clusters=n)\n",
    "        labels = clust.fit_predict(df)\n",
    "        r2_clust[n] = r2(df, labels)\n",
    "    return r2_clust\n",
    "\n",
    "\n",
    "# Set up the clusterers\n",
    "kmeans = KMeans(\n",
    "    init='k-means++',\n",
    "    n_init=20,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "hierarchical = AgglomerativeClustering(\n",
    "    metric='euclidean'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "857320de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining the R² scores for each cluster solution on demographic variables\n",
    "r2_scores = {}\n",
    "r2_scores['kmeans'] = get_r2_scores(df_eng1, kmeans)\n",
    "\n",
    "for linkage in ['complete', 'average', 'single', 'ward']:\n",
    "    r2_scores[linkage] = get_r2_scores(\n",
    "        df_eng1, hierarchical.set_params(linkage=linkage)\n",
    "    )\n",
    "\n",
    "pd.DataFrame(r2_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5473e0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the R² scores for each cluster solution on demographic variables\n",
    "pd.DataFrame(r2_scores).plot.line(figsize=(10,7))\n",
    "\n",
    "plt.title(\"Demographic Variables:\\nR² plot for various clustering methods\\n\")\n",
    "plt.legend(title=\"Cluster methods\")\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.ylabel(\"R² metric\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70ce0d9-43ac-4fbb-9479-8c048c25fd1e",
   "metadata": {},
   "source": [
    "Based on the R² plot the correct number of clusters might be 3 or 4, but the choice isn't clear."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66844a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmclust = KMeans(n_clusters=4, init='k-means++', n_init=15, random_state=1)\n",
    "kmclust.fit(df_eng1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80166345-3101-40b0-81b0-432ebc530965",
   "metadata": {},
   "source": [
    "We are going to do the silhouette_score to decide the final number of clusters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c76c6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from:\n",
    "# https://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html#sphx-glr-auto-examples-cluster-plot-kmeans-silhouette-analysis-py\n",
    "\n",
    "range_clusters = range(1, 11)\n",
    "\n",
    "# Storing average silhouette metric\n",
    "avg_silhouette = []\n",
    "for nclus in range_clusters:\n",
    "    # Skip nclus == 1\n",
    "    if nclus == 1:\n",
    "        continue\n",
    "    \n",
    "    # Create a figure\n",
    "    fig = plt.figure(figsize=(13, 7))\n",
    "\n",
    "    # Initialize the KMeans object with n_clusters value and a random generator\n",
    "    # seed of 10 for reproducibility.\n",
    "    kmclust = KMeans(n_clusters=nclus, init='k-means++', n_init=15, random_state=1)\n",
    "    cluster_labels = kmclust.fit_predict(df_eng1)\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed clusters\n",
    "    silhouette_avg = silhouette_score(df_eng1, cluster_labels)\n",
    "    avg_silhouette.append(silhouette_avg)\n",
    "    print(f\"For n_clusters = {nclus}, the average silhouette_score is : {silhouette_avg}\")\n",
    "\n",
    "# The average silhouette plot\n",
    "# The inertia plot\n",
    "plt.figure(figsize=(9,5))\n",
    "plt.plot(range_clusters[1:], ## Plot X-axis; Why range_clusters[1:] ? Remember we skipped k=1 in the cell above\n",
    "         avg_silhouette)     ## Plot Y-axis\n",
    "\n",
    "plt.ylabel(\"Average silhouette\")\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.title(\"Average silhouette plot over clusters\", size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f969b30a-ba75-4a98-9692-f9885503f79f",
   "metadata": {},
   "source": [
    "Based on the graph above the choice is more clear. We are going to choose 3 clusters. The gain in silhouette score between 3 and 4 is very low. With 3 clusters, the results are simpler to interpret and visualize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b3fd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-running the Hierarchical clustering based on the correct number of clusters\n",
    "kmclust = KMeans(n_clusters=3, init='k-means++', n_init=15, random_state=1)\n",
    "kmclust_labels = kmclust.fit_predict(df_eng1)\n",
    "df_eng1['kmlust_labels'] = kmclust_labels\n",
    "\n",
    "df_eng1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f55d842",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_profiles(df_eng1, ['kmlust_labels'], (20,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4b124df",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### SOM + K-means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "aafb0326",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng2 = df[purchase_behavior]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb236218-4e74-4f09-9d73-2fdfb045e523",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### SOM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca11e675",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(80)\n",
    "\n",
    "sm = sompy.SOMFactory().build(\n",
    "    df_eng2.values, \n",
    "    mapsize=[10, 10], \n",
    "    initialization='random', \n",
    "    neighborhood='gaussian',\n",
    "    training='batch',\n",
    "    lattice='hexa',\n",
    "    component_names=purchase_behavior\n",
    ")\n",
    "sm.train(n_job=1, verbose='info', train_rough_len=120, train_finetune_len=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b32056-72b1-4a44-a107-d4afb597cc24",
   "metadata": {},
   "source": [
    "#### Choosing the best number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3baf8d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "inertia = []\n",
    "for n_clus in range(1,11): \n",
    "    kmclust = KMeans(n_clusters=n_clus, init='k-means++', n_init=20, random_state=80)\n",
    "    kmclust.fit(df_eng2)\n",
    "    inertia.append(kmclust.inertia_)\n",
    "\n",
    "plt.figure(figsize=(9,5))\n",
    "plt.plot(range(1,11),inertia,color = 'blue')\n",
    "plt.ylabel(\"Inertia: SSw\")\n",
    "plt.xlabel(\"Number of clusters\")\n",
    "plt.title(\"Inertia plot over clusters\", size=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5873ab4-f663-4fde-a861-bc878a075858",
   "metadata": {},
   "source": [
    "Beyond 3 clusters, the decrease in inertia slows down, which suggests diminishing returns for adding more clusters.\n",
    "\n",
    "The \"elbow point\" appears to be at 3 clusters, where the rate of improvement in inertia reduction becomes less pronounced."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508d82a8-05ae-499b-b744-99a9eed46545",
   "metadata": {},
   "source": [
    "#### HitMapView"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "702d1eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3,init='k-means++', n_init=20, random_state=42)\n",
    "nodeclus_labels = kmeans.fit_predict(sm.codebook.matrix)\n",
    "sm.cluster_labels = nodeclus_labels  # setting the cluster labels of sompy\n",
    "\n",
    "hits = HitMapView(8,8,\"Clustering\", text_size=10)\n",
    "hits.show(sm, anotate=True, onlyzeros=False, labelsize=7, cmap=\"Pastel1\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a251047a-d185-46ba-8732-56dbd6036e4d",
   "metadata": {},
   "source": [
    "#### Final clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65dee468",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = sm.codebook.matrix\n",
    "\n",
    "df_somk = pd.DataFrame(nodes, columns=purchase_behavior)\n",
    "df_somk['som_kmeans_labels'] = nodeclus_labels\n",
    "df_somk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "c471d0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmus_map = sm.find_bmu(df_eng2.values)[0]  #get bmus for each observation in df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "526b8eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bmus = pd.DataFrame(\n",
    "    np.concatenate((df_eng2, np.expand_dims(bmus_map,1)), axis=1),\n",
    "    index=df_eng2.index, columns=np.append(df_eng2.columns,\"BMU\")\n",
    ")\n",
    "df_bmus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e00af0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_somk_1 = df_bmus.merge(df_somk['som_kmeans_labels'], 'left', left_on=\"BMU\", right_index=True)\n",
    "\n",
    "df_somk_1.drop('BMU', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19049719",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_somk_1.groupby('som_kmeans_labels')[purchase_behavior].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d6f29d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_profiles(df_somk_1, ['som_kmeans_labels'], (20,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5230b107",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### SOM + Hierarquical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "fb558ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng3 = df[purchase_behavior]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dfb691-b23a-4bf2-a46d-1cd0191f32c6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### SOM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca295874",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(80)\n",
    "\n",
    "sm = sompy.SOMFactory().build(\n",
    "    df_eng3.values, \n",
    "    mapsize=[10, 10], \n",
    "    initialization='random', \n",
    "    neighborhood='gaussian',\n",
    "    training='batch',\n",
    "    lattice='hexa',\n",
    "    component_names=purchase_behavior\n",
    ")\n",
    "sm.train(n_job=1, verbose='info', train_rough_len=120, train_finetune_len=120)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f8f16c-6fdf-4058-afa9-5e8860a47db6",
   "metadata": {},
   "source": [
    "#### Choosing the best number of clusters with Hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf037cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "linkage = 'ward'\n",
    "distance = 'euclidean'\n",
    "hclust = AgglomerativeClustering(linkage=linkage, metric=distance, distance_threshold=0, n_clusters=None)\n",
    "hclust.fit_predict(df_eng3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90801db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = np.zeros(hclust.children_.shape[0])\n",
    "n_samples = len(hclust.labels_)\n",
    "\n",
    "# hclust.children_ contains the observation ids that are being merged together\n",
    "# At the i-th iteration, children[i][0] and children[i][1] are merged to form node n_samples + i\n",
    "for i, merge in enumerate(hclust.children_):\n",
    "    # track the number of observations in the current cluster being formed\n",
    "    current_count = 0\n",
    "    for child_idx in merge:\n",
    "        if child_idx < n_samples:\n",
    "            # If this is True, then we are merging an observation\n",
    "            current_count += 1  # leaf node\n",
    "        else:\n",
    "            # Otherwise, we are merging a previously formed cluster\n",
    "            current_count += counts[child_idx - n_samples]\n",
    "    counts[i] = current_count\n",
    "\n",
    "# the hclust.children_ is used to indicate the two points/clusters being merged (dendrogram's u-joins)\n",
    "# the hclust.distances_ indicates the distance between the two points/clusters (height of the u-joins)\n",
    "# the counts indicate the number of points being merged (dendrogram's x-axis)\n",
    "linkage_matrix = np.column_stack(\n",
    "    [hclust.children_, hclust.distances_, counts]\n",
    ").astype(float)\n",
    "\n",
    "# Plot the corresponding dendrogram\n",
    "sns.set()\n",
    "fig = plt.figure(figsize=(11,5))\n",
    "# The Dendrogram parameters need to be tuned\n",
    "y_threshold = 90\n",
    "dendrogram(linkage_matrix, truncate_mode='level', p=5, color_threshold=y_threshold, above_threshold_color='k')\n",
    "plt.hlines(y_threshold, 0, 1000, colors=\"r\", linestyles=\"dashed\")\n",
    "plt.title(f'Hierarchical Clustering - {linkage.title()}\\'s Dendrogram')\n",
    "plt.xlabel('Number of points in node (or index of point if no parenthesis)')\n",
    "plt.ylabel(f'{distance.title()} Distance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1022bd0b-bcfa-4407-bb0a-0bd0802fe605",
   "metadata": {},
   "source": [
    "The threshold (red line) intersects just below a noticeable \"gap\" in the dendrogram.\n",
    "Above this threshold, the vertical distances between clusters are much larger, meaning clusters are more distinct.\n",
    "\n",
    "Based on this analysis 6 is the right choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d49f055-cada-4af2-9ce9-7f356d1291bb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### HitMapView"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18eba398",
   "metadata": {},
   "outputs": [],
   "source": [
    "hierclust = AgglomerativeClustering(n_clusters=6, linkage='ward')\n",
    "node_hier_label= hierclust.fit_predict(sm.codebook.matrix)\n",
    "sm.cluster_labels = node_hier_label  # setting the cluster labels of sompy\n",
    "\n",
    "hits  = HitMapView(6,6,\"Clustering\",text_size=10)\n",
    "hits.show(sm, anotate=True, onlyzeros=False, labelsize=7, cmap=cm.Greens)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5890db49-a0aa-4b89-b3d6-a63e13c286f4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### Final Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e038c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = sm.codebook.matrix\n",
    "\n",
    "hnodes = pd.DataFrame(nodes, columns=purchase_behavior)\n",
    "hnodes['som_hierar_labels'] = node_hier_label\n",
    "hnodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f5171f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "bmus_ = sm.find_bmu(df_eng3.values)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7d7ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bmus = pd.DataFrame(\n",
    "    np.concatenate((df_eng3, np.expand_dims(bmus_,1)), axis=1),\n",
    "    index=df_eng3.index, columns=np.append(df_eng3.columns,\"BMU\")\n",
    ")\n",
    "df_bmus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "ec1a7189",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get cluster labels for each observation\n",
    "df_somh = df_bmus.merge(hnodes['som_hierar_labels'], 'left', left_on=\"BMU\", right_index=True)\n",
    "\n",
    "df_somh.drop('BMU', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5004bcfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_profiles(df_somh, ['som_hierar_labels'], (20,7))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bc43bed",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### DBSCAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "cf839a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eng4 = df[purchase_behavior]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a6ddd11-bc5f-4d86-9993-69100ac0e528",
   "metadata": {},
   "source": [
    "#### Choosing the right number of eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36bf9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Radius of cluster\n",
    "neigh = NearestNeighbors(n_neighbors=27)\n",
    "neigh.fit(df_eng4)\n",
    "distances, _ = neigh.kneighbors(df_eng4)\n",
    "distances = np.sort(distances[:, -1])\n",
    "plt.plot(distances[10000:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e09e2c-3ba2-488a-b3f3-4f9387b28b8e",
   "metadata": {},
   "source": [
    "One more time the right eps isn't clear in the graph above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd06629",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(distances[10000:])\n",
    "plt.axis([15000, 23000, 0,0.4])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ecf16c6-73c3-4052-9b32-2f59b24f94f4",
   "metadata": {},
   "source": [
    "After zooming in we can see that the \"elbow\" appears to be somewhere around the 0.25 - 0.30 range on the y-axis, which suggests that eps might be in this range. There isn't a choice that is 100% right. We are going to choose eps= 0.30 but it is a little bit subjective."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d947cd-eca3-4af8-9089-10f0785c3a3b",
   "metadata": {},
   "source": [
    "#### Choosing the right number of min_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982a0e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "for min_samples in range(2, 15):  \n",
    "        dbscan = DBSCAN(eps=0.30, min_samples=min_samples)\n",
    "        dbscan_labels = dbscan.fit_predict(df_eng4)\n",
    "            \n",
    "        dbscan_n_clusters = len(set(dbscan_labels)) - (1 if -1 in dbscan_labels else 0)\n",
    "            \n",
    "        n_noise = list(dbscan_labels).count(-1)\n",
    "            \n",
    "        if dbscan_n_clusters > 0:\n",
    "            print(f\"min_samples: {min_samples}, clusters: {dbscan_n_clusters}, noise:{n_noise}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90b0457-c000-443a-87a2-42cd393ed3a2",
   "metadata": {},
   "source": [
    "While increasing min_samples beyond 4 maintains the same number of clusters, it significantly increases noise points:\n",
    "\n",
    " - min_samples = 6 results in 33 noise points.\n",
    " - min_samples = 10 results in 66 noise points.\n",
    " - min_samples = 12 results in 101 noise points.\n",
    "   \n",
    "By choosing min_samples = 4, we include more borderline points in clusters while still maintaining clear groupings.\n",
    "\n",
    "Smaller min_samples values lower the density threshold for forming clusters, resulting in additional, less meaningful clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecafb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBSCAN(eps=0.30, min_samples= 4,n_jobs=4)\n",
    "dbscan_labels = dbscan.fit_predict(df_eng4)\n",
    "\n",
    "dbscan_clusters = len(np.unique(dbscan_labels))\n",
    "print(\"Number of estimated clusters : %d\" % dbscan_clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc3ae8d-fb20-4922-8aa8-927c2e11dd71",
   "metadata": {},
   "source": [
    "#### Final clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ec08bbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dbscan = pd.concat([df_eng4, pd.Series(dbscan_labels, name='dbscan_labels', index=df_eng4.index)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3015729a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_profiles(\n",
    "    df = df_dbscan, \n",
    "    label_columns = ['dbscan_labels'], \n",
    "    figsize = (20, 7), \n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd84364",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dbscan.groupby('dbscan_labels')[purchase_behavior].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a32643-bc42-4156-9896-d368049067b3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d475f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.concat([df_eng1, df_somk_1, df_somh, df_dbscan], ignore_index=True)\n",
    "\n",
    "\n",
    "label_columns = ['kmlust_labels', 'som_kmeans_labels', 'som_hierar_labels', 'dbscan_labels']\n",
    "\n",
    "cluster_profiles(combined_df, label_columns, figsize=(20, 20),compar_titles = [\"Hierarchical + K-means\", \"SOM + K-means\", \"SOM + Hierarchical\", \"DBSCAN\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "513f8b50",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 3. Final clusters for each segmentation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "a5e09ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_socio = df[demographics_preferences]\n",
    "df_3 = df[purchase_behavior]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6bb5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_socio = df_socio.reset_index(drop=True)\n",
    "df_3 = df_3.reset_index(drop=True)\n",
    "\n",
    "df_analysis = pd.concat([df_socio, df_3], axis=1)\n",
    "df_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed0e55d-803c-4a83-abab-10cbd95cd7da",
   "metadata": {},
   "source": [
    "According to the several methods of clustering used to each segmentation, we decide that 3 clusters and 3 clusters are the best number for demographics_preferences and purchase_behavior respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "1cb3c4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the right clustering (algorithm and number of clusters) for each perspective\n",
    "hclust_socio = KMeans(\n",
    "    n_clusters=3, \n",
    "    init='k-means++', \n",
    "    n_init=15, \n",
    "    random_state=1)\n",
    "     \n",
    "hc_labels_final = hclust_socio.fit_predict(df_socio)\n",
    "\n",
    "# final cluster solution\n",
    "kmclust4 = KMeans(\n",
    "    n_clusters=3, \n",
    "    init='k-means++', \n",
    "    n_init=15, \n",
    "    random_state=1)\n",
    "\n",
    "km_labels_final = kmclust4.fit_predict(df_3)\n",
    "\n",
    "df['demographics_labels'] = hc_labels_final\n",
    "df['purchase_behavior_labels'] = km_labels_final\n",
    "#df_analysis['Value_labels'] = hc_labels_final\n",
    "#df_analysis['Recency_labels'] = km_labels_final\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b60e2c6d-ae0b-4eba-b0d9-e28f37dec8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count label frequencies (contigency table)\n",
    "\n",
    "pd.crosstab(df['demographics_labels'],\n",
    "            df['purchase_behavior_labels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc37913",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 4. Merging using Hierarchical clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "499227e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Centroids of the concatenated cluster labels\n",
    "df_centroids = df.groupby(['demographics_labels', 'purchase_behavior_labels']).mean()\n",
    "df_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "916de803",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Hierarchical clustering to merge the concatenated cluster centroids\n",
    "linkage = 'ward'\n",
    "hclust = AgglomerativeClustering(\n",
    "    linkage=linkage, \n",
    "    metric='euclidean', \n",
    "    distance_threshold=0, \n",
    "    n_clusters=None\n",
    ")\n",
    "hclust_labels = hclust.fit_predict(df_centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dcc473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adapted from:\n",
    "# https://scikit-learn.org/stable/auto_examples/cluster/plot_agglomerative_dendrogram.html#sphx-glr-auto-examples-cluster-plot-agglomerative-dendrogram-py\n",
    "\n",
    "# create the counts of samples under each node (number of points being merged)\n",
    "counts = np.zeros(hclust.children_.shape[0])\n",
    "n_samples = len(hclust.labels_)\n",
    "\n",
    "# hclust.children_ contains the observation ids that are being merged together\n",
    "# At the i-th iteration, children[i][0] and children[i][1] are merged to form node n_samples + i\n",
    "for i, merge in enumerate(hclust.children_):\n",
    "    # track the number of observations in the current cluster being formed\n",
    "    current_count = 0\n",
    "    for child_idx in merge:\n",
    "        if child_idx < n_samples:\n",
    "            # If this is True, then we are merging an observation\n",
    "            current_count += 1  # leaf node\n",
    "        else:\n",
    "            # Otherwise, we are merging a previously formed cluster\n",
    "            current_count += counts[child_idx - n_samples]\n",
    "    counts[i] = current_count\n",
    "\n",
    "# the hclust.children_ is used to indicate the two points/clusters being merged (dendrogram's u-joins)\n",
    "# the hclust.distances_ indicates the distance between the two points/clusters (height of the u-joins)\n",
    "# the counts indicate the number of points being merged (dendrogram's x-axis)\n",
    "linkage_matrix = np.column_stack(\n",
    "    [hclust.children_, hclust.distances_, counts]\n",
    ").astype(float)\n",
    "\n",
    "# Plot the corresponding dendrogram\n",
    "sns.set()\n",
    "fig = plt.figure(figsize=(11,5))\n",
    "# The Dendrogram parameters need to be tuned\n",
    "y_threshold = 3\n",
    "dendrogram(linkage_matrix, \n",
    "           truncate_mode='level', \n",
    "           labels=df_centroids.index, p=5, \n",
    "           color_threshold=y_threshold, \n",
    "           above_threshold_color='k')\n",
    "\n",
    "plt.hlines(y_threshold, 0, 1000, colors=\"r\", linestyles=\"dashed\")\n",
    "plt.title(f'Hierarchical Clustering - {linkage.title()}\\'s Dendrogram')\n",
    "plt.xlabel('Number of points in node (or index of point if no parenthesis)')\n",
    "plt.ylabel(f'Euclidean Distance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f82b7bf6-e982-4bb2-b6b9-3f03a7395644",
   "metadata": {},
   "source": [
    "At this level, the dendrogram splits into 4 distinct clusters before merging into larger clusters.\n",
    "Beyond this point, the vertical distances between merges (heights of the black lines) increase significantly, indicating that merging clusters further would group dissimilar data points together.\n",
    "Cutting the dendrogram at this level yields well-separated clusters based on the structure of the tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d286b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-running the Hierarchical clustering based on the correct number of clusters\n",
    "hclust = AgglomerativeClustering(\n",
    "    linkage='ward', \n",
    "    metric='euclidean', \n",
    "    n_clusters=3\n",
    ")\n",
    "hclust_labels = hclust.fit_predict(df_centroids)\n",
    "df_centroids['hclust_labels'] = hclust_labels\n",
    "\n",
    "df_centroids  # centroid's cluster labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a851807",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapper between concatenated clusters and hierarchical clusters\n",
    "cluster_mapper = df_centroids['hclust_labels'].to_dict()\n",
    "cluster_mapper\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9083f7f5-e4e6-41b4-9e96-83d9d2b26ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ = df.copy()\n",
    "# df_2 = df_analysis.copy()\n",
    "\n",
    "# Mapping the hierarchical clusters on the centroids to the observations\n",
    "df_['merged_labels'] = df_.apply(\n",
    "    lambda row: cluster_mapper[\n",
    "        (row['demographics_labels'], row['purchase_behavior_labels'])\n",
    "    ], axis=1\n",
    ")\n",
    "\n",
    "'''df_2['merged_labels'] = df_2.apply(\n",
    "    lambda row: cluster_mapper[\n",
    "        (row['Value_labels'], row['Recency_labels'])\n",
    "    ], axis=1\n",
    ")\n",
    "df_ca_analysis['merged_labels'] = df_ca_analysis.apply(\n",
    "        lambda row: cluster_mapper[\n",
    "        (row['Value_labels'], row['Recency_labels'])\n",
    "    ], axis=1\n",
    ")\n",
    "# Merged cluster centroids\n",
    "df_ca_analysis.groupby('merged_labels').mean()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef452bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.groupby('merged_labels').mean(numeric_only=True)[metric_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd2ef141",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge cluster contigency table\n",
    "# Getting size of each final cluster\n",
    "df_counts = df_.groupby('merged_labels')\\\n",
    "    .size()\\\n",
    "    .to_frame()\n",
    "\n",
    "df_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038746b1-1738-4e19-926f-62933ac1a7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the product and behavior labels\n",
    "df_counts = df_counts\\\n",
    "    .rename({v:k for k, v in cluster_mapper.items()})\\\n",
    "    .reset_index()\n",
    "df_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1da3979-4e64-4543-8923-f5797036d1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_counts['demographics_labels'] = df_counts['merged_labels'].apply(lambda x: x[0])\n",
    "df_counts['purchase_behavior_labels'] = df_counts['merged_labels'].apply(lambda x: x[1])\n",
    "\n",
    "\n",
    "df_counts.pivot(values=0, index='demographics_labels', columns='purchase_behavior_labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "d7ce9221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting df to have the final product, behavior and merged clusters\n",
    "df = df_.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a01ed05-d085-4b50-8c64-1b8984a8260c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104a795a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050002ad-a12c-472c-88d6-f086298a64c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a139fdd",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 5.Cluster Analysis \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5669052-1729-4d29-a0d3-23fd583cfda3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Cluster profiles graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babf42ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Profilling each cluster (product, behavior, merged)\n",
    "cluster_profiles(\n",
    "    df = df, \n",
    "    label_columns = ['demographics_labels', 'purchase_behavior_labels', 'merged_labels'], \n",
    "    figsize = (28, 13), \n",
    "    compar_titles = [\"Demographic clustering\", \"Purchase behavior clustering\", \"Merged clusters\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741eb830-412f-45a5-bf77-fb30455d5050",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Profiling with the numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e60be2-8306-40b7-98ac-e76bb8dd953c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_.groupby('merged_labels').mean(numeric_only=True)[metric_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c43aeb-c690-4b10-98c2-d5be2d157d5b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Merged Label: 0.0\n",
    "\n",
    "#### Key Observations:\n",
    "- Customers in this group show **higher-than-average `log_order_rate_per_week` (2.02)** and **`log_amount_spent_per_week` (1.89)**. This suggests that they are **high-frequency purchasers with significant spending habits**.\n",
    "- They prefer **higher average product prices (0.13)** and show a **positive `log_vendor_count` (0.31)**, indicating a willingness to purchase from a wide variety of vendors.\n",
    "- Negative `chain_percentage` (-0.11) suggests **less likelihood to shop at chain stores**.\n",
    "\n",
    "#### Actionable Insights:\n",
    "- **Target this group with premium products** and exclusive, high-value promotions to align with their spending habits and preferences.\n",
    "- **Focus on independent vendors** and unique offerings rather than chain stores.\n",
    "- Highlight products that **encourage high-frequency purchasing and repeat buying**.\n",
    "\n",
    "---\n",
    "\n",
    "### Merged Label: 1.0\n",
    "\n",
    "#### Key Observations:\n",
    "- Customers in this group have a **significant positive `chain_percentage` (0.60)**, indicating a **strong preference for chain stores**.\n",
    "- **Lower-than-average spending** is reflected in **negative `log_order_rate_per_week` (-0.21)** and **`log_amount_spent_per_week` (-0.34)**.\n",
    "- They prefer **lower average product prices (-0.29)** and show **slightly positive recency (-0.06)**, indicating **less frequent but recent purchasing**.\n",
    "\n",
    "#### Actionable Insights:\n",
    "- **Target this group with promotions at chain stores**, focusing on **discounts and bundled offers** to encourage higher spending.\n",
    "- Highlight **value-for-money products** with lower price points.\n",
    "- Leverage campaigns promoting **loyalty programs** or discounts for recent purchases to increase their engagement.\n",
    "\n",
    "---\n",
    "\n",
    "### Merged Label: 2.0\n",
    "\n",
    "#### Key Observations:\n",
    "- Customers in this group display **low `chain_percentage` (-1.19)**, suggesting a **strong preference for independent vendors or niche products**.\n",
    "- They are **moderate spenders**, as reflected in **`log_order_rate_per_week` (0.36)** and **`log_amount_spent_per_week` (-0.05)**.\n",
    "- Their preference for **higher-priced products (0.53)** suggests a **mix of selective yet quality-conscious purchasing**.\n",
    "\n",
    "#### Actionable Insights:\n",
    "- **Focus on unique, high-quality products** from independent vendors to match their preferences.\n",
    "- Highlight **personalized offers** to increase spending without relying on chain-store promotions.\n",
    "- **Target campaigns for customers seeking premium quality** and niche offerings.\n",
    "\n",
    "---\n",
    "\n",
    "### Refined Marketing Insights\n",
    "- **For Merged Label 0.0**: Premium, high-value campaigns for independent vendor offerings with a focus on loyalty.\n",
    "- **For Merged Label 1.0**: Budget-conscious promotions targeted at chain stores with a focus on driving higher engagement and purchases.\n",
    "- **For Merged Label 2.0**: Highlight high-quality, niche products and personalized campaigns to encourage spending from selective buyers.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a67ec6f8-2b8d-438e-9e9a-c2c8db77123c",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Profiling with unused / categorical features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeeca3d1-c9a3-4137-b1e6-f303469728dc",
   "metadata": {},
   "source": [
    "### Importing categoricals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b6e47117-45b7-480c-a9f4-a3053afc8b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_labels_analysis= df_.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6e06df-9fe5-4035-a336-ee802510f080",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_cleaned_df = pd.read_csv(\"data_cleaned.csv\")\n",
    "merged_df = pd.merge(merged_labels_analysis, data_cleaned_df, how=\"outer\")\n",
    "columns_to_drop = metric_features + ['customer_id','demographics_labels', 'purchase_behavior_labels','total_amount_spent' ]\n",
    "merged_df_dropped = merged_df.drop(columns=columns_to_drop, errors='ignore')\n",
    "grouped_df = merged_df_dropped.groupby('merged_labels').mean().T\n",
    "grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87111e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add this cell to export the merged labels along with the numerical data\n",
    "# Assuming df is your final DataFrame and merged_labels are your final cluster labels\n",
    "df['cluster_labels'] = merged_labels  # Add the cluster labels to the DataFrame\n",
    "pickle.dump(df, open(\"preprocessed_data_numerical_merged_labels.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb88ace-5018-4149-a57b-3e568fde6796",
   "metadata": {},
   "source": [
    "Marketing Insights\n",
    "\n",
    "For Merged Label 0.0:\n",
    "\n",
    " - Focus on \"DELIVERY\" promotions, as they resonate most with this group.\n",
    " - Emphasize Asian cuisine in marketing campaigns.\n",
    " - Target customer_region_8670, customer_region_2360, and customer_region_4660.\n",
    " - Consider campaigns balanced across City_2 and City_3.\n",
    "\n",
    "For Merged Label 1.0:\n",
    "\n",
    " - Highlight \"FREEBIE\" promotions to attract this segment.\n",
    " - Showcase a diverse range of cuisines, particularly Japanese and Italian.\n",
    " - Target customers in City_3 and regions like customer_region_2360 and customer_region_4660.\n",
    "   \n",
    "For Merged Label 2.0:\n",
    "\n",
    " - Promote \"DELIVERY\" campaigns, with additional focus on Italian and Japanese cuisines.\n",
    " - Concentrate marketing efforts in City_2 and customer_region_4660.\n",
    " - Leverage digital payment options (DIGI) to encourage transactions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c233e42-c101-4327-b191-c75c85a1b6e8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 6. Cluster visualization using t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "de3f7ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is step can be quite time consuming\n",
    "two_dim = TSNE(random_state=42).fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd58e298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# t-SNE visualization\n",
    "pd.DataFrame(two_dim).plot.scatter(x=0, y=1, c=df['merged_labels'], colormap='tab10', figsize=(15,10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7368af",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# 7. Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "3ee2051b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ss_variables(df):\n",
    "    \"\"\"Get the SS for each variable\n",
    "    \"\"\"\n",
    "    ss_vars = df.var() * (df.count() - 1)\n",
    "    return ss_vars\n",
    "\n",
    "def r2_variables(df, labels):\n",
    "    \"\"\"Get the R² for each variable\n",
    "    \"\"\"\n",
    "    sst_vars = get_ss_variables(df)\n",
    "    ssw_vars = np.sum(df.groupby(labels).apply(get_ss_variables))\n",
    "    return 1 - ssw_vars/sst_vars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8b8f5c-c859-432b-bc56-be5b25be16f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are essentially decomposing the R² into the R² for each variable\n",
    "r2_variables(df[metric_features + ['merged_labels']], 'merged_labels').drop('merged_labels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56a34e7",
   "metadata": {},
   "source": [
    "### Using a Decision Tree\n",
    "We get the normalized total reduction of the criterion (gini or entropy) brought by that feature (also known as Gini importance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f2f65ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc750ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the data\n",
    "X = df[metric_features]\n",
    "y = df.merged_labels\n",
    "\n",
    "# Splitting the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Fitting the decision tree\n",
    "dt = DecisionTreeClassifier(random_state=42, max_depth=3)\n",
    "dt.fit(X_train, y_train)\n",
    "print(\"It is estimated that in average, we are able to predict {0:.2f}% of the customers correctly\".format(dt.score(X_test, y_test)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a07b4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assessing feature importance\n",
    "pd.Series(dt.feature_importances_, index=X_train.columns).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f9600d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizing the decision tree\n",
    "dot_data = export_graphviz(dt, out_file=None, \n",
    "                           feature_names=X.columns.to_list(),\n",
    "                           filled=True,\n",
    "                           rounded=True,\n",
    "                           special_characters=True)\n",
    "g = graphviz.Source(dot_data)\n",
    "\n",
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc64146f-4311-4d18-9118-a57ed4071228",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
